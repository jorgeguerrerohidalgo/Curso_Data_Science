{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc9e59b",
   "metadata": {},
   "source": [
    "# Desafío - Máquinas de Soporte Vectorial\n",
    "\n",
    "- Para realizar este desafío debes haber estudiado previamente todo el material disponibilizado correspondiente a la unidad.\n",
    "- Una vez terminado el desafío, comprime la carpeta que contiene el desarrollo de los requerimientos solicitados y sube el .zip en el LMS.\n",
    "- Desarrollo desafío:\n",
    "    - El desafío se debe desarrollar de manera Individual\n",
    "    - Para la realización del desafío necesitarás apoyarte del archivo Apoyo Desafío - Máquinas de Soporte Vectorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f023532",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "Para esta sesión trabajaremos con la base de datos sobre cáncer mamario de Wisconsin. El objetivo es desarrollar un Clasificador mediante Máquinas de Soporte de Vectores que predica de forma adecuada en base a una serie de atributos sobre la composición del núcleo de una célula mamaria. Para más detalles técnicos asociados a la base de datos, pueden hacer click en el <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names\">link</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fa6bb",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Preparar el ambiente de trabajo\n",
    "- Importe todas las librerías a utilizar.\n",
    "- Fije los parámetros de los gráficos con `plt.Rcparams`.\n",
    "- Excluya las columnas `id` y `Unnamed: 32` del set de datos.\n",
    "- Codifique el vector objetivo `diagnosis` a dato numérico para poder procesarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6c88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para importar las librerías y el set de datos\n",
    "# importamos las librerias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# import func as gfx\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57f64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para explorar las frecuencias del vector objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530ba1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para codificar el vector objetivo, asignando 1 a la clase mayoritaria y -1 a la minoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2811a0",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Visualizando la distribución de los atributos\n",
    "- Para cada uno de los atributos, grafique los histogramas condicional a cada clase del vector objetivo.\n",
    "- Agregue las medias correspondientes y reporte a grandes rasgos cuáles son los atributos con una mayor similitud en la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db63fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para graficar los histogramas solicitados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0972752",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfe8d1",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Estimando el porcentaje de overlap en los atributos\n",
    "- Parte de las virtudes de las Máquinas de Soporte Vectorial es la capacidad de lidiar con clases no separables mediante el proceso de kernelización. Resulta que un aspecto importante que muchas veces se obvia es medir la noseparabilidad de los atributos, condicional a cada clase del vector objetivo.\n",
    "- El procedimiento para estimar el rango de noseparabilidad entre clases se implementa en Python de la siguiente manera:\n",
    "```python\n",
    "def histogram_overlap(df, attribute, target, perc=100):\n",
    "    # get lower bound\n",
    "    empirical_lower_bound = np.floor(df[attribute].min())\n",
    "    \n",
    "    # get upper bound\n",
    "    empirical_upper_bound = np.ceil(df[attribute].max())\n",
    "    \n",
    "    # preserve histograms\n",
    "    tmp_hist_holder = dict()\n",
    "    \n",
    "    # for each target class\n",
    "    tar_values = df[target].unique()\n",
    "    for unique_value in tar_values:\n",
    "        # get histogram\n",
    "        tmp, _ = np.histogram(\n",
    "            df[df[target] == unique_value][attribute],   # for a specific attribute\n",
    "            bins=perc,   # define percentage\n",
    "            range=[empirical_lower_bound, empirical_upper_bound]   # limit empirical range for comparison\n",
    "        )\n",
    "        \n",
    "        # append to dict\n",
    "        tmp_hist_holder[f\"h_{unique_value}\"] = tmp\n",
    "        \n",
    "    get_minima = np.minimum(\n",
    "        tmp_hist_holder[f\"h_{tar_values[0]}\"],\n",
    "        tmp_hist_holder[f\"h_{tar_values[1]}\"]\n",
    "    )\n",
    "    \n",
    "    intersection = np.true_divide(\n",
    "        np.sum(get_minima),\n",
    "        np.sum(tmp_hist_holder[f\"h_{tar_values[0]}\"])\n",
    "    )\n",
    "    \n",
    "    return intersection\n",
    "```\n",
    "- La intersección devolverá el porcentaje de comunalidad entre ambas clases, donde mayores niveles indican una mayor comunalidad.\n",
    "- Utilizando la función, generará un data frame donde almacenará el nombre del atributo y su porcentaje. Ordene este data frame de forma descendente y preserve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11091623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir la función entregada\n",
    "def histogram_overlap(df, attribute, target, perc=100):\n",
    "    # get lower bound\n",
    "    empirical_lower_bound = np.floor(df[attribute].min())\n",
    "    \n",
    "    # get upper bound\n",
    "    empirical_upper_bound = np.ceil(df[attribute].max())\n",
    "    \n",
    "    # preserve histograms\n",
    "    tmp_hist_holder = dict()\n",
    "    \n",
    "    # for each target class\n",
    "    tar_values = df[target].unique()\n",
    "    for unique_value in tar_values:\n",
    "        # get histogram\n",
    "        tmp, _ = np.histogram(\n",
    "            df[df[target] == unique_value][attribute],   # for a specific attribute\n",
    "            bins=perc,   # define percentage\n",
    "            range=[empirical_lower_bound, empirical_upper_bound]   # limit empirical range for comparison\n",
    "        )\n",
    "        \n",
    "        # append to dict\n",
    "        tmp_hist_holder[f\"h_{unique_value}\"] = tmp\n",
    "        \n",
    "    get_minima = np.minimum(\n",
    "        tmp_hist_holder[f\"h_{tar_values[0]}\"],\n",
    "        tmp_hist_holder[f\"h_{tar_values[1]}\"]\n",
    "    )\n",
    "    \n",
    "    intersection = np.true_divide(\n",
    "        np.sum(get_minima),\n",
    "        np.sum(tmp_hist_holder[f\"h_{tar_values[0]}\"])\n",
    "    )\n",
    "    \n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959b52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para generar el DatFrame solicitado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5daeb6",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Selección del modelo por GridSearchCV\n",
    "- Entrene una serie de modelos SVC con los siguientes hiper parámetros:\n",
    "    - `C: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]`\n",
    "    - `gamma: [0.0000001, 0.0001, 0.001, 0.01, 0.1, 1, 10]`\n",
    "    - Validaciones cruzadas: 10\n",
    "    \n",
    "- Genere un heatmap en base a los puntajes estimados con `GridSearchCV`. _Tip_: Vea cómo acceder a la llave `mean_test_score` en el diccionario `cv_results_`.\n",
    "- Reporte en qué rango de cada hiper parámetro el modelo presenta un desempeño eficiente. Reporte la mejor combinación de hiper parámetros y el desempeño en la muestra de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47acb1d",
   "metadata": {},
   "source": [
    "### Digresión: Un par de elementos a considerar en la implementación de GridSearchCV\n",
    "Si trabajamos con `sklearn.model_selection.GridSearchCV`, tan solo haciendo la división en dos muestras es suficiente, incorporando los conjuntos `X_train` y `y_train` a nuestro objeto instanciado y preservando `X_test` e `y_test` como una muestra de validación externa. Si tenemos un archivo de testing externo, se recomienda no hacer división.\n",
    "\n",
    "-  El objeto creado con `sklearn.model_selection.GridSearchCV` sigue la misma funcionalidad de cualquier método de estimación de scikit-learn, con los pasos de Instanciar y Entrenar. Este objeto tendrá muchos elementos a considerar:\n",
    "    - `sklearn.model_selection.GridSearchCV.cv_results_` devolverá un diccionario donde las llaves representarán distintas métricas y los valores representarán el desempeño de cada modelo.\n",
    "    - `split`: Indicará la métrica específica en cada validación cruzada y combinación de hiper parámetros.\n",
    "    - `time`: Indicará el tiempo de ejecución en cada modelo.\n",
    "    - Por lo general trabajaremos con `mean_test_score` y `mean_train_score` que representa la media de CV para cada combinación de hiper parámetros.\n",
    "    - `sklearn.model_selection.GridSearchCV.best_estimator_` devuelve un modelo listo para entrenar con la mejor combinación de hiper parámetros.\n",
    "    - `sklearn.model_selection.GridSearchCV.best_score_` devuelve el desempeño promedio del modelo en el testing interno. Si es un problema de clasificación devolverá Accuracy, si es un problema de regresión devolverá MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b495938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para dividir las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2675efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir el pipeline (use kernel rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f67cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir la grilla de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c9dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir el objeto GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b1210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para entrenar la grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c062b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir la función para reportar los heatmaps de hiperparámetros\n",
    "def report_heatmaps(cv_trained):\n",
    "    param1 = tuple(cv_trained.param_grid.keys())[0]\n",
    "    param2 = tuple(cv_trained.param_grid.keys())[1]\n",
    "    \n",
    "    # Mejores parámetros subconjuntos para test\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(\n",
    "        cv_trained.cv_results_['mean_test_score'].reshape(len(cv_trained.param_grid[param1]), len(cv_trained.param_grid[param2])),\n",
    "        cmap='Blues',\n",
    "        annot=True,\n",
    "        xticklabels=cv_trained.param_grid[param2],\n",
    "        yticklabels=cv_trained.param_grid[param1],\n",
    "        cbar=False\n",
    "    )\n",
    "    \n",
    "    plt.ylabel(param1)\n",
    "    plt.xlabel(param2)\n",
    "    plt.title('Test CV')\n",
    "    \n",
    "    # Mejores parámetros subconjuntos para train\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(\n",
    "        cv_trained.cv_results_['mean_train_score'].reshape(len(cv_trained.param_grid[param1]), len(cv_trained.param_grid[param2])),\n",
    "        cmap='Blues',\n",
    "        annot=True,\n",
    "        xticklabels=cv_trained.param_grid[param2],\n",
    "        yticklabels=cv_trained.param_grid[param1],\n",
    "        cbar=False\n",
    "    )\n",
    "    \n",
    "    plt.ylabel(param1)\n",
    "    plt.xlabel(param2)\n",
    "    plt.title('Train CV')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63dc4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para llamar la función definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748f7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para reportar los mejores hiperparámetros y mejor puntaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e863c",
   "metadata": {},
   "source": [
    "### Ejercicio 5: Validación del modelo en el Test set sample\n",
    "- Genere las predicciones del Test set sample en base a la mejor combinación de hiperparámetros.\n",
    "- Genere un reporte con las métricas de desempeño clásicas para los modelos de clasificación.\n",
    "- Comente en qué casos el modelo presenta un desempeño deficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc99b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para reportar las métricas del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc2966",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
