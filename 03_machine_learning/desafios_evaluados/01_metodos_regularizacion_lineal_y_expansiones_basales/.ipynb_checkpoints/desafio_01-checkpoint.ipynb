{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío - Expansiones basales\n",
    "\n",
    "● Para realizar este desafío debes haber estudiado previamente todo el material disponibilizado correspondiente a la unidad.\n",
    "\n",
    "● Una vez terminado el desafío, comprime la carpeta que contiene el desarrollo de los requerimientos solicitados y sube el .zip en el LMS.\n",
    "\n",
    "● Desarrollo desafío:\n",
    "    \n",
    "    ○ El desafío se debe desarrollar de manera Individual.\n",
    "    \n",
    "    ○ Para la realización del desafío necesitarás apoyarte del archivo Apoyo Desafío - Expansiones basales.\n",
    "\n",
    "## Descripción\n",
    "\n",
    "● Una aplicación interesante de los modelos predictivos es poder predecir propiedades de materiales compuestos a partir de diferentes combinaciones en el proceso y creación de estos.\n",
    "\n",
    "● Para este desafío trabajaremos con un dataset que contiene diferentes medidas de materiales con los que se hace la mezcla de concreto.\n",
    "\n",
    "● Nuestra tarea será utilizar estas medidas para predecir la capacidad de resistir fuerzas compresivas de vigas de concreto, a esta capacidad de soportar fuerzas que buscan reducir la superficie o volumen de un cuerpo se le conoce como fuerza compresiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preparar el ambiente de trabajo\n",
    "\n",
    "● Importe los módulos clásicos del trabajo en ciencia de datos.\n",
    "\n",
    "● El archivo tiene el nombre compresive_strength_concrete.csv. Importe y genere estadísticas descriptivas.\n",
    "\n",
    "● En esta actividad su tarea será predecir la fuerza compresiva del concreto a partir de las medidas en la mezcla, para esto, utilice un modelo aditivo generalizado de la librería pyGAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lazypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets\n",
    "#!pip install pandas-profiling\n",
    "#!pip install lazypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importación de librerias\n",
    "# librerias clasicas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import missingno as msngo\n",
    "\n",
    "# analisis exploratorio \n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# librerias de machine learning\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "# librerias LazyPredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# otros\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "import func as fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el archivos compresive_strength_concrete.csv en nuestro DataSet\n",
    "df = pd.read_csv('compresive_strength_concrete.csv')\n",
    "# visualizamos los primeros 10 registros del df\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos estadisticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Descripción\n",
    "\n",
    "● El vector objetivo tiene el nombre de Concrete compressive strength(MPa, megapascals)\n",
    "\n",
    "● Los nombres de las variables son muy poco amigables, dado que contienen espacios, paréntesis y otros elementos difíciles de referenciar. Se sugiere (pero no se obliga) renombrar las variables o acceder a éstas mediante notación de índice iloc.\n",
    "\n",
    "● Inspeccione el tipo de datos de la base de datos, fijándose en su naturaleza y distribución. Decide si es necesario normalizarlos/escalarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de cararcteres en nombre de las variables, para eliminar espacios, mayusculas y parentesis\n",
    "df.columns = df.columns.map(lambda x: str(x).lower().replace(' ', '_'))\n",
    "df.columns = df.columns.map(lambda x: str(x).lower().replace('(', ''))\n",
    "df.columns = df.columns.map(lambda x: str(x).lower().replace(')', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio de nombres a variables\n",
    "df = df.rename(columns={'cement_component_1kg_in_a_m^3_mixture':'cement',\n",
    "                        'blast_furnace_slag_component_2kg_in_a_m^3_mixture':'blast_furnace',\n",
    "                        'fly_ash_component_3kg_in_a_m^3_mixture':'fly_ash',\n",
    "                        'water__component_4kg_in_a_m^3_mixture':'water',\n",
    "                        'superplasticizer_component_5kg_in_a_m^3_mixture':'superplasticizer',\n",
    "                        'coarse_aggregate__component_6kg_in_a_m^3_mixture':'coarse_aggregate',\n",
    "                        'fine_aggregate_component_7kg_in_a_m^3_mixture':'fine_aggregate',\n",
    "                        'age_day':'age',\n",
    "                        'concrete_compressive_strengthmpa,_megapascals_':'concrete'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos la dimensionalidad del dataset\n",
    "print(f'''El dataset contiene\n",
    "Numero de filas: {df.shape[0]}\n",
    "Numero de columnas: {df.shape[1]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos que no existan datos perdidos\n",
    "msngo.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos el tipo de datos de cada una de las columnas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df['concrete'])\n",
    "plt.title(f'Distribución para variable objetivo: Concrete')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion distribucion vector objetivo\n",
    "sns.distplot(x = df['concrete'])\n",
    "sns.rugplot(x = df['concrete'])\n",
    "plt.title(f'Distribución para variable objetivo: concrete')\n",
    "plt.axvline(df['concrete'].mean())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis exploratorio mediante ProfileReport de Pandas.\n",
    "perfil = ProfileReport(df, title=\"Reporte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfil.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos la composición del dataset, indicando en detalle cada una de las caracteristicas de las columnas.\n",
    "fx.summary_drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vars = ['cement', 'blast_furnace', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age', 'concrete']\n",
    "\n",
    "for i in range(len(list_vars)):\n",
    "        fx.dist_box(df[list_vars[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Modelo\n",
    "● En base al vector objetivo, decida el mejor modelo e importe con pygam. Condicional a esto, importe las métricas de desempeño asociadas.\n",
    "\n",
    "● Genere conjuntos de entrenamiento y validación.\n",
    "\n",
    "● Genere un primer modelo sin implementar la función gridsearch. Reporte el hiper parámetro lam así como las métricas de desempeño asociadas.\n",
    "\n",
    "● Genere un segundo modelo implementando gridsearch en lambda con un logspace entre -3 y 3. Comente sobre el mejor hiper parámetro y sus métricas de desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx.summary_drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determinamos las columnas de forma aleatoria segun el analisis exploratorio\n",
    "sub = df[['age','cement','water','coarse_aggregate','fine_aggregate','superplasticizer']]\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(sub, df['concrete'], test_size=.3, random_state=2404)\n",
    "\n",
    "# ajustamos el estandarizador sobre el conjunto de entrenamiento (para que aprenda la media y desv. est.)\n",
    "scaler = StandardScaler().fit(X_train_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con el estandarizador ajustamos sobre entrenamiento, transformamos el conjunto de entrenamiento con esta estandarizacion\n",
    "X_train = pd.DataFrame(scaler.transform(X_train_pre), columns= X_train_pre.columns)\n",
    "\n",
    "# transformamos el conjunto de pruebas con el estandarizador ajustado sobre entrenamiento\n",
    "X_test = pd.DataFrame(scaler.transform(X_test_pre), columns= X_test_pre.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = np.logspace(-3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = [lams]*len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5), fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genere un primer modelo sin implementar la función gridsearch.\n",
    "gam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(model, x_test, y_test):\n",
    "    preds = model.predict(x_test)\n",
    "    print(f'Test R2: {r2_score(y_test, preds)}')\n",
    "    print(f'Test MSE: {mean_squared_error(y_test,preds)}')\n",
    "    print(f'Test Median Absolute Error: {median_absolute_error(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Metricas para el primer modelo entregado con lambda: {gam.lam}\\n')\n",
    "report_metrics(gam,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genere un segundo modelo implementando gridsearch\n",
    "gam_2 = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5), fit_intercept=True)\n",
    "gam_2.gridsearch(X_train.values, y_train.values, lam = lams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Metricas para el segundo modelo entregado con lambda: {gam_2.lam}\\n')\n",
    "report_metrics(gam_2,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo modelo presenta mejores resultados que el segundo mediante gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Dependencia Parcial\n",
    "\n",
    "● En base al mejor modelo, reporte el comportamiento de la dependencia parcial de cada atributo.\n",
    "\n",
    "● Para ello, genere una función que tenga como argumento de entrada el modelo estimado y devuelva una grilla con todos los gráficos de dependencia parcial.\n",
    "\n",
    "● Reporte brevemente sobre qué atributos están asociados a mayores y menores. niveles de resistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependencia_parcial(model):\n",
    "    fig, axs = plt.subplots(2,3, figsize = (20,6));\n",
    "    titles = X_train.columns\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        XX = model.generate_X_grid(term=i)\n",
    "        ax.plot(XX[:,i], model.partial_dependence(term=i, X=XX))\n",
    "        ax.plot(XX[:,i], model.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "        ax.scatter(X_train[titles[i]],\n",
    "               [0] * len(X_train[titles[i]]),\n",
    "               marker = '|', alpha = .5)\n",
    "        ax.set_title(titles[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics(gam, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencias parciales del primer modelo (gam sin gridsearch)\n",
    "dependencia_parcial(gam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics(gam_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencias parciales del segundo modelo (gam con gridsearch)\n",
    "dependencia_parcial(gam_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d09f4fe54c3df51b24a8aa16b16d6bc9db83d2a27fa52ba8d86cb0d08fbb39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
